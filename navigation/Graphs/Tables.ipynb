{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d7b5ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import EventCollection\n",
    "import numpy as np\n",
    "\n",
    "class pathdata(object):\n",
    "    def __init__(self, sourcefile):\n",
    "        self.source = sourcefile\n",
    "        self.perc = {90: [], 98: []}\n",
    "        self.percav = {}\n",
    "        \n",
    "        self.fill_data()\n",
    "\n",
    "        \n",
    "        \n",
    "    def fill_data(self):\n",
    "        with open(self.source, \"r\") as myfile:\n",
    "            file_learned = True\n",
    "            for line in myfile:\n",
    "                is_valid = re.search(\"Target: \\d+\", line)\n",
    "                if is_valid:\n",
    "                    p = int(re.search(\"\\d+\", is_valid.group()).group())\n",
    "                    err = float(re.search(\"\\d+\\.\\d+\", re.search(\"Err: \\d+\\.\\d+\", line).group()).group())\n",
    "                    self.perc[p].append(err)\n",
    "                if file_learned and re.search(\"nan\", line):\n",
    "                    file_learned = False\n",
    "                    print(\"Error occurred in file {}\".format(self.source))\n",
    "        for p in self.perc.keys():\n",
    "            self.percav[p] = np.nanmean(self.perc[p])\n",
    "            \n",
    "            \n",
    "            \n",
    "class summarydata_withstd(object):\n",
    "    def __init__(self, files):\n",
    "        self.files = files\n",
    "        self.avgerror = 0\n",
    "        self.avgerror_std = None\n",
    "        self.avgsparsity = 0\n",
    "        self.avgsparsity_std = None\n",
    "        \n",
    "        self.percs = {}\n",
    "        self.percs_std = {}\n",
    "        \n",
    "        self.summary()\n",
    "        \n",
    "    def summary(self):\n",
    "        pathdatadict = {}\n",
    "        percs1 = {90: [], 98: []}\n",
    "        for i in range(len(self.files)):\n",
    "            pathdatadict[i] = pathdata(self.files[i])\n",
    "            for p in percs1.keys():\n",
    "                percs1[p].append(pathdatadict[i].percav[p])\n",
    "            \n",
    "        for p in percs1.keys():\n",
    "            self.percs[p] = np.nanmean(percs1[p])\n",
    "            self.percs_std[p] = np.nanstd(percs1[p])\n",
    "            \n",
    "            \n",
    "class tablemaker(object):\n",
    "    def __init__(self, filedict):\n",
    "        self.filedict = filedict\n",
    "        self.filenames = []\n",
    "        self.ps = {90: [], 98: []}\n",
    "        self.ps_std = {90: [], 98: []}\n",
    "        \n",
    "        self.makedata()\n",
    "        \n",
    "    def makedata(self):\n",
    "        for f in self.filedict.keys():\n",
    "            self.filenames.append(f)\n",
    "            fsum = summarydata_withstd(self.filedict[f])\n",
    "            for p in self.ps.keys():\n",
    "                self.ps[p].append(fsum.percs[p])\n",
    "                self.ps_std[p].append(fsum.percs_std[p])\n",
    "                \n",
    "    def maketable(self):\n",
    "        print(f'\\\\begin{{tabular}}{{c|' + ''.join(['c' for i in range(len(self.filenames))]) + f'}} \\\\hline')\n",
    "        print(' & ' + ' & '.join(self.filenames) + f' \\\\\\\\ \\\\hline')\n",
    "        for p in self.ps.keys():\n",
    "            print('{{\\\\bf {}\\\\% Sparse Err.}} & '.format(str(p)) + ' & '.join(['{:.2f} ({:.2f})'.format(self.ps[p][i], self.ps_std[p][i]) for i in range(len(self.ps[p]))]) + f' \\\\\\\\')\n",
    "        print(f'\\\\end{{tabular}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe8f44cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c|cccc} \\hline\n",
      " & Torus & No reg. & $L_1$ & Perm. DoG \\\\ \\hline\n",
      "{\\bf 90\\% Sparse Err.} & 6.29 (1.17) & 78.64 (12.64) & 72.96 (20.30) & 9.66 (0.30) \\\\\n",
      "{\\bf 98\\% Sparse Err.} & 95.87 (1.33) & 96.18 (0.89) & 95.77 (1.22) & 94.58 (1.60) \\\\\n",
      "\\end{tabular}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3554897/1678024297.py:29: RuntimeWarning: Mean of empty slice\n",
      "  self.percav[p] = np.nanmean(self.perc[p])\n"
     ]
    }
   ],
   "source": [
    "testdict = { }\n",
    "testdict['Torus'] = ['FullSparse/torusl1dog{}.txt'.format(k) for k in range(5)]\n",
    "testdict['No reg.'] = ['FullSparse/noreg{}.txt'.format(k) for k in range(5)]\n",
    "testdict['$L_1$'] = ['FullSparse/l1{}.txt'.format(k) for k in range(5)]\n",
    "testdict['Perm. DoG'] = ['FullSparse/perml1dog{}.txt'.format(k) for k in range(5)]\n",
    "\n",
    "\n",
    "test = tablemaker(testdict)\n",
    "test.maketable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87a64413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c|ccccc} \\hline\n",
      " & Torus & Circle & Sphere & Klein & 6 Torus \\\\ \\hline\n",
      "{\\bf 90\\% Sparse Err.} & 6.29 (1.17) & 25.95 (33.92) & 69.12 (12.06) & 5.89 (0.58) & 14.52 (5.84) \\\\\n",
      "{\\bf 98\\% Sparse Err.} & 95.87 (1.33) & 94.53 (0.78) & 87.75 (5.88) & 96.07 (0.65) & 94.96 (1.36) \\\\\n",
      "\\end{tabular}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3554897/1678024297.py:29: RuntimeWarning: Mean of empty slice\n",
      "  self.percav[p] = np.nanmean(self.perc[p])\n"
     ]
    }
   ],
   "source": [
    "modulidict = { }\n",
    "modulidict['Torus'] = ['FullSparse/torusl1dog{}.txt'.format(k) for k in range(5)]\n",
    "modulidict['Circle'] = ['FullSparse/circlel1dog{}.txt'.format(k) for k in range(5)]\n",
    "modulidict['Sphere'] = ['FullSparse/spherel1dog{}.txt'.format(k) for k in range(5)]\n",
    "modulidict['Klein'] = ['FullSparse/kleinl1dog{}.txt'.format(k) for k in range(5)]\n",
    "modulidict['6 Torus'] = ['FullSparse/torus6l1dog{}.txt'.format(k) for k in range(5)]\n",
    "\n",
    "\n",
    "moduli = tablemaker(modulidict)\n",
    "moduli.maketable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b7ac91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c|ccc} \\hline\n",
      " & DoG & Diffusion & Ripple \\\\ \\hline\n",
      "{\\bf 90\\% Sparse Err.} & 6.29 (1.17) & 24.19 (34.50) & 24.19 (34.50) \\\\\n",
      "{\\bf 98\\% Sparse Err.} & 95.87 (1.33) & 94.55 (0.37) & 94.55 (0.37) \\\\\n",
      "\\end{tabular}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3554897/1678024297.py:29: RuntimeWarning: Mean of empty slice\n",
      "  self.percav[p] = np.nanmean(self.perc[p])\n"
     ]
    }
   ],
   "source": [
    "inhibdict = {}\n",
    "inhibdict['DoG'] = ['FullSparse/torusl1dog{}.txt'.format(k) for k in range(5)]\n",
    "inhibdict['Diffusion'] = ['FullSparse/torusl1sq{}.txt'.format(k) for k in range(5)]\n",
    "inhib = tablemaker(inhibdict)\n",
    "inhib.maketable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2840cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fac35e3",
   "metadata": {},
   "source": [
    "# Lottery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14b0bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import EventCollection\n",
    "import numpy as np\n",
    "\n",
    "class pathdata(object):\n",
    "    def __init__(self, sourcefile):\n",
    "        self.source = sourcefile\n",
    "        self.perc = {\"90\\\\% Sparse\": [], \"Lottery\": []}\n",
    "        self.percav = {}\n",
    "        \n",
    "        self.fill_data()\n",
    "\n",
    "        \n",
    "        \n",
    "    def fill_data(self):\n",
    "        with open(self.source, \"r\") as myfile:\n",
    "            file_learned = True\n",
    "            is_lot = False\n",
    "            for line in myfile:\n",
    "                is_valid = re.search(\"Validator: \", line)\n",
    "                if not is_lot:\n",
    "                    is_lot = re.search(\"Sparsity: 90\", line)\n",
    "                    if is_valid:\n",
    "                        err = float(re.search(\"\\d+\\.\\d+\", re.search(\"Err: \\d+\\.\\d+\", line).group()).group())\n",
    "                        self.perc[\"90\\\\% Sparse\"].append(err)\n",
    "                if is_lot: \n",
    "                    if is_valid:\n",
    "                        err = float(re.search(\"\\d+\\.\\d+\", re.search(\"Err: \\d+\\.\\d+\", line).group()).group())\n",
    "                        self.perc[\"Lottery\"].append(err)\n",
    "                if file_learned and re.search(\"nan\", line):\n",
    "                    file_learned = False\n",
    "                    print(\"Error occurred in file {}\".format(self.source))\n",
    "        for p in self.perc.keys():\n",
    "            self.percav[p] = np.nanmean(self.perc[p])\n",
    "            \n",
    "            \n",
    "            \n",
    "class summarydata_withstd(object):\n",
    "    def __init__(self, files):\n",
    "        self.files = files\n",
    "        self.avgerror = 0\n",
    "        self.avgerror_std = None\n",
    "        self.avgsparsity = 0\n",
    "        self.avgsparsity_std = None\n",
    "        \n",
    "        self.percs = {}\n",
    "        self.percs_std = {}\n",
    "        \n",
    "        self.summary()\n",
    "        \n",
    "    def summary(self):\n",
    "        pathdatadict = {}\n",
    "        percs1 = {\"90\\\\% Sparse\": [], \"Lottery\": []}\n",
    "        for i in range(len(self.files)):\n",
    "            pathdatadict[i] = pathdata(self.files[i])\n",
    "            for p in percs1.keys():\n",
    "                percs1[p].append(pathdatadict[i].percav[p])\n",
    "            \n",
    "        for p in percs1.keys():\n",
    "            self.percs[p] = np.nanmean(percs1[p])\n",
    "            self.percs_std[p] = np.nanstd(percs1[p])\n",
    "            \n",
    "            \n",
    "class tablemaker(object):\n",
    "    def __init__(self, filedict):\n",
    "        self.filedict = filedict\n",
    "        self.filenames = []\n",
    "        self.ps = {\"90\\\\% Sparse\": [], \"Lottery\": []}\n",
    "        self.ps_std = {\"90\\\\% Sparse\": [], \"Lottery\": []}\n",
    "        \n",
    "        self.makedata()\n",
    "        \n",
    "    def makedata(self):\n",
    "        for f in self.filedict.keys():\n",
    "            self.filenames.append(f)\n",
    "            fsum = summarydata_withstd(self.filedict[f])\n",
    "            for p in self.ps.keys():\n",
    "                self.ps[p].append(fsum.percs[p])\n",
    "                self.ps_std[p].append(fsum.percs_std[p])\n",
    "                \n",
    "    def maketable(self):\n",
    "        print(f'\\\\begin{{tabular}}{{c|' + ''.join(['c' for i in range(len(self.filenames))]) + f'}} \\\\hline')\n",
    "        print(' & ' + ' & '.join(self.filenames) + f' \\\\\\\\ \\\\hline')\n",
    "        for p in self.ps.keys():\n",
    "            print('{{\\\\bf {}\\\\% Sparse Err.}} & '.format(str(p)) + ' & '.join(['{:.2f} ({:.2f})'.format(self.ps[p][i], self.ps_std[p][i]) for i in range(len(self.ps[p]))]) + f' \\\\\\\\')\n",
    "        print(f'\\\\end{{tabular}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37615f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c|cccc} \\hline\n",
      " & Torus & No reg. & $L_1$ & Perm. DoG \\\\ \\hline\n",
      "{\\bf 90\\% Sparse\\% Sparse Err.} & 5.37 (0.00) & 82.43 (0.00) & 74.83 (0.00) & 10.57 (0.00) \\\\\n",
      "{\\bf Lottery\\% Sparse Err.} & 9.42 (0.00) & 68.83 (0.00) & 59.26 (0.00) & 34.97 (0.00) \\\\\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "testdict = { }\n",
    "testdict['Torus'] = ['Lottery/torusl1dog{}.txt'.format(k) for k in range(1, 2)]\n",
    "testdict['No reg.'] = ['Lottery/noreg{}.txt'.format(k) for k in range(1, 2)]\n",
    "testdict['$L_1$'] = ['Lottery/l1{}.txt'.format(k) for k in range(1, 2)]\n",
    "testdict['Perm. DoG'] = ['Lottery/perml1dog{}.txt'.format(k) for k in range(1, 2)]\n",
    "\n",
    "\n",
    "test = tablemaker(testdict)\n",
    "test.maketable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1c40c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c|ccccc} \\hline\n",
      " & Torus & Circle & Sphere & Klein & 6 Torus \\\\ \\hline\n",
      "{\\bf 90\\% Sparse\\% Sparse Err.} & 5.37 (0.00) & 9.60 (0.00) & 23.85 (0.00) & 5.48 (0.00) & 38.12 (0.00) \\\\\n",
      "{\\bf Lottery\\% Sparse Err.} & 9.42 (0.00) & 96.18 (0.00) & 94.19 (0.00) & 9.74 (0.00) & 94.22 (0.00) \\\\\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "modulidict = { }\n",
    "modulidict['Torus'] = ['Lottery/torusl1dog{}.txt'.format(k) for k in range(1, 2)]\n",
    "modulidict['Circle'] = ['Lottery/circlel1dog{}.txt'.format(k) for k in range(1, 2)]\n",
    "modulidict['Sphere'] = ['Lottery/spherel1dog{}.txt'.format(k) for k in range(1, 2)]\n",
    "modulidict['Klein'] = ['Lottery/kleinl1dog{}.txt'.format(k) for k in range(1, 2)]\n",
    "modulidict['6 Torus'] = ['Lottery/torus6l1dog{}.txt'.format(k) for k in range(1, 2)]\n",
    "\n",
    "\n",
    "moduli = tablemaker(modulidict)\n",
    "moduli.maketable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ab32a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c|cc} \\hline\n",
      " & DoG & Square \\\\ \\hline\n",
      "{\\bf 90\\% Sparse\\% Sparse Err.} & 5.37 (0.00) & 5.82 (0.00) \\\\\n",
      "{\\bf Lottery\\% Sparse Err.} & 9.42 (0.00) & 10.74 (0.00) \\\\\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "inhibdict = {}\n",
    "inhibdict['DoG'] = ['Lottery/torusl1dog{}.txt'.format(k) for k in range(1, 2)]\n",
    "inhibdict['Square'] = ['Lottery/torusl1sq{}.txt'.format(k) for k in range(1, 2)]\n",
    "inhib = tablemaker(inhibdict)\n",
    "inhib.maketable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc2334e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
